Tacotron ë…¼ë¬¸ â–¶
> [Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/abs/1703.10135)

Tacotron2 ë…¼ë¬¸ â–¶
> [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)

## Cotatron ê³¼ Tacotron
cotatron ì€ speaker ì˜ íŠ¹ì§•ì— êµ¬ì• ë°›ì§€ ì•Šê³  any-to-many ë°©ì‹ì˜ ìŒì„±ë³€ì¡°ë¥¼ í•  ìˆ˜ ìˆëŠ”ë°, ì—¬ê¸°ì—ì„œ ê°€ì¥ í•µì‹¬ì´ ë˜ëŠ” ê²ƒì´ tts ëª¨ë¸ì˜ í™œìš©ì´ë‹¤. 

ì´ tts ëª¨ë¸ë¡œ ì‚¬ìš©ëœ ê²ƒì´ Tacotron 2 ì¸ë°, ì´ì œë¶€í„°  Tacotron ì˜ êµ¬ì¡°ì— ëŒ€í•´ ì•Œì•„ë³´ì.

âœ” `seq2seq ê³¼ bahdanau attention ì— ëŒ€í•´ ìˆ™ì§€í•œ ë‹¤ìŒ ì½ëŠ” ê²ƒì„ ì¶”ì²œí•œë‹¤`
## what is Tacotron?
![tacotron](https://gitlab.com/hanish3464/voice-conversion/uploads/b08bd2a834c36bc566b313f17731092b/tacotron.png)
```
tacotronì€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ìŒì„±ì„ ì¶œë ¥í•˜ëŠ” tts(text-to-speech) ëª¨ë¸ ì¤‘ í•˜ë‚˜ì´ë‹¤.
(2017ë…„ ë°œí‘œ)
Tacotron 2 ëŠ” íƒ€ì½”ë“œë¡ 1ê³¼ WaveNet ê°™ì€ ì´ì „ ë…¼ë¬¸ì—ì„œ ì–»ì€ ì•„ì´ë””ì–´ë¥¼ ê²°í•©í•˜ê³  ê°œì„ ì‚¬í•­ì„ 
ì¶”ê°€í•œ ë²„ì „ì´ë‹¤.
(2018 ë…„ ë°œí‘œ)

* WaveNet : ë§¤ìš° ê°•ë ¥í•œ ì˜¤ë””ì˜¤ ìƒì„± ëª¨ë¸, ì„±ëŠ¥ì´ ë§¤ìš° ì¢‹ì•„ Tacotron ì˜ Vocoder ë¡œë„
ì‚¬ìš©ë¨. ê·¸ëŸ¬ë‚˜ ë„ˆë¬´ ëŠë¦¬ê³  end-to-end ê°€ ì•„ë‹ˆë¼ëŠ” ë‹¨ì ì´ ìˆìŒ.
```
* íŠ¹ì§•
```
* ê¸°ì¡´ì˜ ëª¨ë¸ë“¤ì´ ë¹„í•´ End-To-End TTS systme ì´ê¸° ë–„ë¬¸ì— ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
(ê°„ë‹¨í•˜ê²Œ <text, audio> í˜ì–´ë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ.)

* ê·¸ëŸ¬ë‚˜ ê²°ê³¼ë¬¼ì˜ ê¸¸ì´ê°€ Input ë³´ë‹¤ í›¨ì”¬ ê¸¸ë‹¤ëŠ” ì ì—ì„œ Error ê°€ ë°œìƒí•˜ê±°ë‚˜ ê²°ê³¼ë¬¼ì—
ì¼ê´€ì„±ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‹ í˜¸ ë ˆë²¨ì—ì„œ í° ë³€í™”ì— ëŒ€ì²˜í•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ì„ í•™ìŠµì‹œí‚¬ í•„ìš”ê°€
ìˆë‹¤.
```

## Architecture
`ìš°ì„  tacotron 1 ì˜ êµ¬ì¡°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•œë‹¤.`
![tacotron3](https://gitlab.com/hanish3464/voice-conversion/uploads/4edafa827c8bd3bfaa04770721d778ab/tacotron3.png)
```
tacotron ì€ ê¸°ë³¸ì ìœ¼ë¡œ encoder-edcoder êµ¬ì¡°ë¥¼ ê°€ì§„ seq2seq ëª¨ë¸ì´ë‹¤.
ê¸°ë³¸ì ì¸ í˜•íƒœì˜ seq2seq ê°€ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ê°ê° RNN ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬
íƒ€ì½”íŠ¸ë¡ ì—ì„œ ë””ì½”ë”ëŠ” RNN ì˜ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆì§€ë§Œ ì¸ì½”ë”ëŠ” ì¼ë°˜ì ì¸ ì‹ ê²½ë§ì˜ êµ¬ì¡°ë¥¼
ê°€ì§€ê³  ìˆë‹¤.

ë˜í•œ ëª¨ë¸ì— attention mechnism ì„ ì´ìš©í•˜ë©°, ê·¸ ì¤‘ Bahdanau ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤.
ì´ attention ì´ cotatron voice conversion decoder ì˜ ì…ë ¥ê°’ì„ ìƒì„±í•˜ëŠ”ë° í•µì‹¬ì ì¸
ê°œë…ì´ë¯€ë¡œ ì£¼ì˜ê¹Šê²Œ ë³¼ í•„ìš”ê°€ ìˆë‹¤.   

ì•„ë˜ì˜ í”„ë¡œì„¸ìŠ¤ ì„¤ëª… íŒŒíŠ¸ì—ì„œ ì²˜ë¦¬íë¦„ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•œë‹¤.
```

## Process
* ì…ì¶œë ¥
```
input : ë¬¸ì¥ í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ embeddings í•œ ê²ƒ

output1 (mel-spectrogram) : ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ê° time step ë§ˆë‹¤ ë‚˜ì˜¤ëŠ” ê²°ê³¼ê°’.
                            mel-spectrogram í˜•íƒœë¥¼ ê°€ì§€ë©° ì‹œê°„ìˆœì„œëŒ€ë¡œ ì¶œë ¥ë¨.
							
output2 (audio) : ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ì¶œë ¥ëœ mel-spectrogram ì„ ê¸°ë°˜ìœ¼ë¡œ audio ë¥¼ ìƒì„±í•¨.
```
![tacotron2](https://gitlab.com/hanish3464/voice-conversion/uploads/c62fc6415f52aea1c90256574866241b/tacotron2.png)

### 1. Encoder
```
Fully Connected Layer ê³¼ 1D Convolutional Layer ê°€ ì„ì—¬ ìˆëŠ” network.
í¬ê²Œ Pre network ì™€ CBHG network ë¡œ ë‚˜ë‰œë‹¤.  

ì•„ì›ƒí’‹ì€ ì…ë ¥ë°°ì—´ê³¼ ë™ì¼í•œ ê°¯ìˆ˜ì˜ ì›ì†Œë¥¼ ê°€ì§€ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •ë¨. 
(ê·¸ë˜ì•¼ attention value ê³„ì‚°ì„ í•  ìˆ˜ ìˆë‹¤.)
```
![tacotron4](https://gitlab.com/hanish3464/voice-conversion/uploads/1b2bae02cbd5e148c7c9bf530f4eb883/tacotron4.png)

â–¶ Pre-net

_input(text embedding)_ â†’ **FC(Dense) â€” ReLU â€” Dropout â€” FC â€” ReLU â€” Dropout**

â–¶ CBHG network

**Conv1D bank â€” Max Pooling â€” Conv1D projection â€” Conv1D Layer**

_Conv1D Layer + First Input_ â†’ **Highway Net(4 layers of FC-ReLU) â€” Bidirectional RNN**

`CBHG ì´ë¯¸ì§€`

![CBHG](https://gitlab.com/hanish3464/voice-conversion/uploads/a9cff66780e3570adfcfa4f49ab4ebad/CBHG.png)

### 2. Decoder
* **content-based tanh attention decoder**
```
attention mechanism ì„ ì‚¬ìš©í•˜ëŠ” seq2seq decoder êµ¬ì¡°ë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•¨.

ë‹¤ìŒì€ ê° time step ë§ˆë‹¤ì˜ ì²˜ë¦¬ê³¼ì •ì´ë‹¤.
```
1. **ì…ë ¥ê°’** : ì´ì „ íƒ€ì„ ìŠ¤íƒ­ì˜ ì¶œë ¥ê°’ (mel-spectrogram í˜•ì‹)
2. pre-net : ì…ë ¥ê°’ ì²˜ë¦¬ (encoder ì˜ pre-net ê³¼ êµ¬ì¡° ë™ì¼)
3. Attention RNN : GRU Cell
4. attention module : **encoder output** ê³¼ **Attention RNN ì…€ì˜ hidden state** ë¥¼ ì´ìš©í•˜ì—¬ Bahdanau ì—°ì‚°ìœ¼ë¡œ Attention valueê³„ì‚°.
5. Decoder RNN : Residual GRU Cell 2ì¸µ 

![tacotron5](https://gitlab.com/hanish3464/voice-conversion/uploads/95fc62029c1170bec42d88b46b110fb8/tacotron5.PNG)


â–¶ tacotron decoder ëŠ” ì´ì „ ë¬¸ì„œë¡œ ì‘ì„±í–ˆë˜ **Bahdanau mechanism ì˜ attention value
 ìˆ˜ì‹**ì„ ì‚¬ìš©í•˜ì§€ë§Œ ë„¤íŠ¸ì›Œí¬ì˜ êµ¬ì¡°ëŠ” ë‹¤ë¥´ë¯€ë¡œ ì£¼ì˜ í•„ìš”

â–¶ 4ë²ˆ ê³¼ì •ì— attention module ê³„ì‚°ì„ í•œë‹¤ê³  ë‚˜ì™€ìˆëŠ”ë°, ê·¸ë¦¼ ìƒìœ¼ë¡œëŠ” rnn íƒ€ì… ìŠ¤íƒ­ ì¤‘ ê°€ì¥ ì™¼ìª½ì˜ attention rnn ì…€ë§Œ ì–´í…ì…˜ ëª¨ë“ˆê³¼ ì—°ê²°ë˜ì–´ ìˆëŠ” ê²ƒì²˜ëŸ¼ í‘œí˜„ë˜ì–´ ìˆë‹¤.

â–¶ í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ **ëª¨ë“  íƒ€ì…ìŠ¤íƒ­ë§ˆë‹¤** attention ëª¨ë“ˆì´ hidden state ê°’ì„ ë°›ì•„ attention value(context vector) ë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒìœ¼ë¡œ ì´í•´í•´ì•¼ í•œë‹¤.

â–¶ Decoder RNN ì˜ ì…ë ¥ê°’ìœ¼ë¡œëŠ” ê³„ì‚°ëœ **CONTEXT VECTOR ì™€ attention rnn ì…€ì˜ hidden state ë¥¼ concatenate** í•œ ê°’ì´ ë“¤ì–´ê°„ë‹¤.

(ê¸°ë³¸ì ìœ¼ë¡œ rnn êµ¬ì¡°ì´ê¸° ë•Œë¬¸ì— ì´ì „ íƒ€ì„ìŠ¤íƒ­ì—ì„œ hidden stateë¥¼ ì „ë‹¬ë°›ìŒ ì´ ê°’ê³¼ ì…ë ¥ê°’ì„ ì´ìš©í•˜ì—¬ ê³„ì‚°.)

![tacotron5-2](https://gitlab.com/hanish3464/voice-conversion/uploads/f8e166a051839f04e1c6f971d879e13d/tacotron5-2.png)

* Seq2seq target with r=3
```
decoderëŠ” ì˜ í•œ íƒ€ì„ìŠ¤íƒ­ë§ˆë‹¤ rê°œì˜ frameë¥¼ ì˜ˆì¸¡.
n(hz) ë¡œ ì˜¤ë””ì˜¤ë¥¼ ìƒ˜í”Œë§í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, (1/n) * r ì´ˆ ê¸¸ì´ì˜ mel-spectrogramì„ 
ì˜ˆì¸¡í•œë‹¤ëŠ” ê²ƒ.

r ê°œì˜ frame ì¤‘ ê°€ì¥ ë§ˆì§€ë§‰ ê²ƒì´ ë‹¤ìŒ íƒ€ì…ìŠ¤íƒ­ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤.
```
### 3. Post-net & vocoder
```
ì´ì „ ë ˆì´ì–´ì—ì„œ output ìœ¼ë¡œ ë‚˜ì˜¨ mel-spectrogram ë¥¼ ì´ìš©í•˜ì—¬ .wav í˜•ì‹ì˜ audio íŒŒì¼ì„ 
ìƒì„±í•œë‹¤. 

ì´ë ‡ê²Œ ëŒ€ì‚¬ text ë¥¼ ì¸í’‹ìœ¼ë¡œ ë„£ìœ¼ë©´ ì•„ì›ƒí’‹ìœ¼ë¡œ audio ê°€ ë‚˜ì˜¤ëŠ” í˜•ì‹ì„ ê°–ì¶”ê³  ìˆê¸° ë•Œë¬¸ì—
End-to-End ë¡œ ê°„í¸í•˜ê²Œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŒ.
```
![tacotron6](https://gitlab.com/hanish3464/voice-conversion/uploads/037d99e83537e7e47b64e4bb9a3388d9/tacotron6.PNG)

â–¶ CBHG ë ˆì´ì–´ : ì´ë¶€ë¶„ì„ post-net ì´ë¼ í•¨. encoderì—ì„œ ì‚¬ìš©ë˜ëŠ” CBHG ë ˆì´ì–´ì™€ ëª‡ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ì œì™¸í•˜ê³ ëŠ” ê±°ì˜ ë™ì¼.

â–¶ Griffin-Lim reconstruction : spectrogram ì„ ë‹¤ì‹œ audio ë¡œ ë§Œë“¤ì–´ ì£¼ëŠ” ì•Œê³ ë¦¬ì¦˜.

----------------
### Learning

```
í•™ìŠµì€ decoder ì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¤ëŠ” mel-spectrogram ê³¼ ì´ê²ƒì´ CBHG ë¥¼ ê±°ì¹œ 
linear-scale spectrogram ë‘ê°€ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•œë‹¤.

ë”°ë¼ì„œ loss ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
```

â–¶ **mel_loss = tf.reduce_mean(tf.abs(mel_outs - mel_targets))**

â–¶ **linear_loss = tf.reduce_mean(tf.abs(linear_outs - linear_targets))**

â–¶ **loss=mel_loss + linear_loss**

* Adam Optimizer ì‚¬ìš© : Learning rate ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¤„ì—¬ë‚˜ê°.


# Tacotron VS Tacotron 2

`ì•„ë˜ëŠ” tacotron 2 ì˜ ì•„í‚¤í…ì²˜ ê·¸ë¦¼ì´ë‹¤.`

![taco2tron_3_](https://gitlab.com/hanish3464/voice-conversion/uploads/573732259fbbbb5ea51bffcaf50444dc/taco2tron_3_.PNG)

ì´ë ‡ê²Œ ë³´ë©´ ìœ„ì—ì„œ ì„¤ëª…í•œ tacotron ê³¼ ì™„ì „íˆ ë‹¤ë¥¸ êµ¬ì¡°ë¥¼ ê°€ì§„ ê²ƒì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, 
**ì‚¬ì‹¤ì€ ê·¸ë˜í”„ë¥¼ ì•„ë˜ì™€ ê°™ì€ í˜•íƒœë¡œ ì¬ë°°ì—´**í•  ìˆ˜ ìˆë‹¤.

![taco2tron_4_](https://gitlab.com/hanish3464/voice-conversion/uploads/ef4ab8ce74c7a0eb842932d7f11e9671/taco2tron_4_.png)
```
ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ tacotron 2 ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ tacotron 1 ê³¼ ìœ ì‚¬í•œ êµ¬ì¡°ë¥¼ ê°€ì§„ë‹¤. 
decoder ë¶€ë¶„ë˜í•œ ê·¸ë¦¼ì´ ì¶•ì•½ë˜ì–´ ë°”ë¡œ ì•Œì•„ë³´ì§€ ëª»í•  ìˆ˜ ìˆì§€ë§Œ, ê¸°ë³¸ tacotron ì²˜ëŸ¼ 
rnn ë„¤íŠ¸ì›Œí¬ë¥¼ ê¸°ë³¸ í‹€ë¡œ í•˜ê³  ì…ë ¥ ë¶€ë¶„ì— pre-net ì´, ì¶œë ¥ ë¶€ë¶„ì— post-net ì´ ìœ„ì¹˜í•˜ê³ 
ìˆë‹¤. 
```
`decoder ë¶€ë¶„ì—ì„œ ì¢€ë” ì„¸ë¶€ì ìœ¼ë¡œ ì–´ë–¤ ì°¨ì´ê°€ ìˆëŠ”ì§€ ë³´ì. ë‹¤ìŒì€ decoder ë¶€ë¶„ì„ í™•ëŒ€í•˜ì—¬ ê¸°ì¡´ tacotron ëª¨ë¸ê³¼ ìµœëŒ€í•œ ë¹„ìŠ·í•œ í˜•íƒœë¡œ ë¬˜ì‚¬í•œ ê·¸ë˜í”„ì˜ ì´ë¯¸ì§€ì´ë‹¤.`
![taco2tron](https://gitlab.com/hanish3464/voice-conversion/uploads/4a7cf9e12ba1c609b270fae5a5c1e798/taco2tron.png)
```
ì—¬ê¸°ì„œ tacotron ê³¼ tacotron2 ì˜ ì°¨ì´ì ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
```

1. CONTEXT VALUE ê°€ Decoder RNN ë¿ë§Œ ì•„ë‹ˆë¼ **ë‹¤ìŒ time step** ì—ì„œ post-net ì„ ê±°ì¹œ spectrogramê³¼ concat ë˜ì–´ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.
2. ê° RNN ì…€ì—ì„œ GRU ê°€ ì•„ë‹Œ **LSTM** ì´ ì‚¬ìš©ëœë‹¤. 
3. POST-NET ì— CBHG ê°€ ì•„ë‹Œ **5ì¸µì˜ CNN ë ˆì´ì–´**ê°€ ì‚¬ìš©ëœë‹¤.
4. spectrogram ì„ wav ë¡œ ë³€í™˜í•˜ëŠ”ë° **WaveNet vocoder ë¥¼ ì‚¬ìš©**í•œë‹¤.
5. vocoder ì˜ ì…ë ¥ì´ linear spectrogram ì´ ì•„ë‹Œ **mel spectrogram** ì´ë‹¤.

`
ìœ„ì˜ ì°¨ì´ì ë“¤ì€ ì „ì²´ì ì¸ êµ¬ì¡°ë¥¼ ë°”ê¿€ì •ë„ëŠ” ì•„ë‹ˆë¯€ë¡œ ê¸°ë³¸ tacotron ì„ ê¸°ë°˜ìœ¼ë¡œ ì´í•´í•˜ë©´ ëœë‹¤.
ì¢€ ë” ê¹Šì€ ì´í•´ê°€ í•„ìš”í•  ê²½ìš° tacotron ì˜ êµ¬í˜„ì²´ ì½”ë“œë¥¼ ì½ì–´ë³´ëŠ” ê²ƒì„ ì¶”ì²œí•œë‹¤. 
`
ğŸ¤”

-------------
Reference : 

[Tacotron ì„¸ë¯¸ë‚˜ - TmaxData NLP - youtube](https://www.youtube.com/watch?v=02odSrfgasI)

[# [Speech Synthesis] Tacotron ë…¼ë¬¸ ì •ë¦¬](https://hcnoh.github.io/2018-12-11-tacotron)

[# ê³ ë“±í•™ìƒì´ í•´ì„í•œ Tacotron2](https://medium.com/wasd/%EA%B3%A0%EB%93%B1%ED%95%99%EC%83%9D-%EC%8B%9C%EC%A0%90%EC%9C%BC%EB%A1%9C-%EB%85%BC%EB%AC%B8%EC%9D%84-%EC%9D%BD%EC%96%B4%EB%B3%B4%EC%9E%90-e6953caf4bf8)

[### ì»´ê³µí•™ë¶€ìƒì´ ì½ì–´ë³´ëŠ” ë…¼ë¬¸ê°ìƒ - Tacotron : Toward End-To-End Speech Synthesis (1)](https://snowapril7758.tistory.com/4?category=760801)
