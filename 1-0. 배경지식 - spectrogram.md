`음성처리와 관련된 모델에서는 왜 mel-spectrogram 포멧으로 데이터를 다루는 것일까 ?`

Spectrogram 의 사전적인 정의는 다음과 같다.
**"웨이브를 푸리에 변환을 통해 주파수 영역에서 표현한 것"**

그러나 이 설명만으로는 정확히 어떻게 변환을 했다는 것인지, 또 왜 이것이 음성 데이터를 변조하는 과정에 필요한 것인지 이해하는데에 무리가 있다. 

![음성웨이브](https://gitlab.com/hanish3464/voice-conversion/uploads/dd676de0474ca5452990e80db46f5381/Untitled.png)

일반적인 음성 데이터는 위와 같이 비주기적인 파형을 가지고 있으며 시간과 진폭의 그래프로 표현될 수 있다.

우선, 주파수 영역에서 표현한다는 것은 음성웨이브를 임의의 입력 신호를 **다양한 주파수를 갖는 주기함수들의 합으로 분해**하여 표현하는 것을 의미한다. 

주기함수는 다양한 종류가 있겠지만 그중에서도 푸리에 변환에서 사용하는 주기함수는 sin, cos 삼각함수이다.

아래 그림 예시의 경우 붉은 색 신호가 입력신호, 뒤의 파란색 신호들은 푸리에 변환(Fourier transform)을 통해 얻어진 주기함수 성분들이다. 각각의 주기함수 성분들을 모두 합치면 원본 붉은색 신호가 된다.

![푸리에_변환](https://gitlab.com/hanish3464/voice-conversion/uploads/c1060330684d32a91e50b9ce50fb78b7/푸리에_변환.png)

여기서 입력 신호는 전파, 음성 신호 등과 같이 시간축(time)에 대해 정의된 신호일 수도 있고 이미지(image) 등과 같이 공간축에 대해 정의된 신호일 수도 있지만, 핵심은 입력 신호를 sin, cos의 주기성분으로 분해한다는 부분이다.


여기까지 읽었다면 이번 프로젝트에서 음성 데이터를 mel spectrogram 으로 바꾸는 이유에 대해 어느정도 직관적으로 이해할 수 있다. 
변조 과정에는 rnn , mel gan 등의 학습 과정이 필요한데 음성데이터가 비주기적인 파형의 형태를 가지고 있는 것 보다는 주기적인 파형들로 분해되어 있는것이 데이터로서 활용하고 해석하기에 더 용이한 것이다.

![Spectorgram](https://gitlab.com/hanish3464/voice-conversion/uploads/4b4d25112e3827df3746eb2c6675e5b0/Untitled__2_.png)

결과로 생성된 Spectrogram 그래프를 보자. 여기서 x축은 시간(Time), y축은 주파수(Frequency), z축은 진폭(Amplitud을 나타낸다. 
z축의 경우 각 x,y 좌표에서 색상으로 표현된다. (그래프 오른쪽의 막대 참고)

Spectrogram 은 기존 웨이브의 영역을 잘게 잘라 해당 영역에 대한  푸리에 변환 결과들을 이어붙여 만들어진다. z축 색상으로부터 알 수 있는 진폭은 기존 웨이브를 구성하고 있는 주기함수들 중, 특정 주파수의 주기함수가 가지는 진폭을 표현한다.

여기서 진폭이 큰 주파수의 성분은 음성웨이브에 끼치는 영향이 크다고 할 수 있다.

## 원리

그렇다면 푸리에 변환의 주파수 성분들은 어떻게 찾아내는 것일까 ?

변환의 원리에 대해서는 다음 영상을 참고하였다.

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/spUNpyF58BY/0.jpg)](https://www.youtube.com/watch?v=spUNpyF58BY)

결론부터 보자면 푸리에 변환은 다음과 같은 수식을 가진다.

![](https://latex.codecogs.com/gif.latex?%5Cdisplaystyle%20%5Chat%7Bh%7D%28t%29%20%3D%20F%5Cleft%5Bh%5Cright%5D%5Cleft%28t%5Cright%29%20%3D%20%5Cint_%7B-%5Cinfty%7D%20%5E%7B%5Cinfty%7D%20e%5E%7B-2%20%5Cpi%20itx%7D%20h%5Cleft%28x%5Cright%29%20%5Cmathrm%7Bd%7Dx)

 위 변환 hat{h}, F[h]를 함수 h의 푸리에 변환이라 정의한다.

이 수식이 나오기까지의 논리는 다음과 같이 설명된다. 

1. **하나의 주파수로 이루어진 주기함수를 원 주위에 감는다.**  
![Fourier1](https://gitlab.com/hanish3464/voice-conversion/uploads/ae56e20ca344d39286223df9498d4404/Fourier1.PNG)
2. **원 주위에 그래프를 감는 주기(Frequency) 를 변경해가며 무게중심(이 예시에서는 x축만 고려) 을 관찰했을 때, 대부분의 주파수에서 무게중심은 비교적 중심에 근접한 위치에서 고르게 분포하지만 감는 주파수와 신호 주파수가 일치하는 지점에서 예외적으로 한쪽으로 치우치게 된다.**
	(여기서 감는 주파수와 신호 주파수를 잘 구분해야 함)
![Fourier2](https://gitlab.com/hanish3464/voice-conversion/uploads/1db8d46aba168e9145aadc7b5c31770f/Fourier2.PNG)

3. **서로 다른 신호들을 합친 그래프를 위와 같은 방식으로 변환 했을때, 그 결과는 각각의 신호를 변환한 결과를 합한것과 일치한다. 따라서 변환결과를 주기함수 분해에 활용할 수 있다.**
![Fourier3](https://gitlab.com/hanish3464/voice-conversion/uploads/e925de9e95411815629fa602668c3fae/Fourier3.PNG)

4. **감은 그래프의 좌표를 복소수로 다룬다면(ex. x축을 실수부 y축을 허수부로) 무게중심의 변동을 하나의 식으로 설명할 수 있다. 복소 평면에서는 오일러의 공식을 이용해 원운동의 좌표를 표현 가능하므로, 복소 지수 함수와 그래프 식을 곱한 것이 감은 그래프의 좌표가 되며, 이것을 적분한 것이 무게중심이 된다.**
![Fourier4](https://gitlab.com/hanish3464/voice-conversion/uploads/280f818920ede1e20ddc770dcbe8c0c6/Fourier4.PNG)

![](https://latex.codecogs.com/gif.latex?%5Coperatorname%20%7Bcis%7D%28%5Ctheta%20%29%3De%5E%7B%7Bi%5Ctheta%20%7D%7D%3D%5Ccos%20%5Ctheta%20&plus;i%5Csin%20%5Ctheta)

= 반지름 1인 원의 오른쪽에서 시작해 θ 각만큼 이동한 위치

![](https://latex.codecogs.com/gif.latex?%5Cdisplaystyle%20%5Chat%7Bh%7D%28t%29%20%3D%20F%5Cleft%5Bh%5Cright%5D%5Cleft%28t%5Cright%29%20%3D%20%5Cint_%7B-%5Cinfty%7D%20%5E%7B%5Cinfty%7D%20e%5E%7B-2%20%5Cpi%20itx%7D%20h%5Cleft%28x%5Cright%29%20%5Cmathrm%7Bd%7Dx)

= 푸리에 변환 수식. 지수에 - 가 붙어 회전방향 반시계

	* 수식에서 적분 범위가 무한대로 되어 있으나 이는 용도에 따라 다르게 설정할 수 있다.

위의 예시에서는 두가지의 주기함수로 구성된 신호를 예시로 하였지만, 실제 음향 데이터는 매우 다양한 주파수로 분해될 것이다.

결론적으로 푸리에 변환을 활용하면 특정 음성웨이브를 다양한 주파수로 분해할 수 있는데, 이것를 그래프상에 표현한 것이 **Spectrogram** 인 것.

## mel-spectrogram
mel-spectrogram 은 사람의 음을 인지하는 기준을 반영하여 일반 Spectrogram을 선형 변환한 것이다. [Hz -> 음계]의 관계는 exponential하기 때문에(hz 와 음계는 지수관계임)  주파수를 바로 다루지 말고, log함수를 통과시켜 mel scale로 바꾼다면, linear하게 다룰 수 있다.
![Mel-spectrogram](https://gitlab.com/hanish3464/voice-conversion/uploads/0b8f6784f95c2ce58d125fe3237c4bfa/Untitled__3_.png)
때문에 위의 이미지에서 spectrogram 에 곱하는 Mel-Filter Matrix 는 Log 함수의 형태를 가지고 있다. 

예를 들어 식이 log(x) 라고 가정하면 원래 Frequency 축에서 <img src="https://latex.codecogs.com/svg.latex?e^a" />였던 지점이 <img src="https://latex.codecogs.com/svg.latex?a" /> 로 바뀌는 식이다. 
물론 실제 Mel_Filter 식은 좀더 복잡하다. 
**다음 수식 참고.**

![](https://latex.codecogs.com/gif.latex?Mel%28f%29%3D2595%5Clog%281&plus;%5Cfrac%7Bf%7D%7B700%7D%29)

## 프로젝트
이 프로젝트의 모델에서는 음성 데이터를 mel-spectrogram 으로 변환한뒤 음성변조 과정을 거쳐 최종적으로 다시 wav 음성파일로 변환하는 vocoding 과정을 거친다.
![project_image](https://gitlab.com/hanish3464/voice-conversion/uploads/19c5ce0675fe961e88545406a1c772a2/project_image.PNG)

푸리에 변환은 역벽환이 가능하며, 특히나 자기자신이 곧 역변환이라 결과 그래프에 푸리에 변환 식을 한번 더 적용하기만 하면 되므로 매우 쉬운 편에 속한다.

spectrogram 은 단순히 푸리에 변환만을 거치는 것이 아닌 FFT 에 절대 제곱을 취하는 과정을 거처 위상 정보를 잃게 된다.
따라서 원래의 음성 신호를 정확하게 복원하는 것을 불가능하며, 이를 위해 수식적인 역변환이 아닌 딥러닝을 활용한 vocoding 모델 **mel-gan**을 사용한다.

--------------
Reference :

[Fourier Transform(푸리에 변환)의 이해와 활용](https://darkpgmr.tistory.com/171)]

[# 푸리에 변환 - 위키백과](https://ko.wikipedia.org/wiki/%ED%91%B8%EB%A6%AC%EC%97%90_%EB%B3%80%ED%99%98)

[But what is Fourier Transform? - Youtube](https://www.youtube.com/watch?v=spUNpyF58BY&feature=emb_logo)

[# 음성인식 기초 이해하기](https://newsight.tistory.com/294)

[Is there a way to invert a spectrogram back to signal](https://stackoverflow.com/questions/58409556/is-there-a-way-to-invert-a-spectrogram-back-to-signal)
