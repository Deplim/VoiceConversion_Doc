### ðŸ’»
>  voice conversion í”„ë¡œì íŠ¸ ë¬¸ì„œ ì €ìž¥ì†Œìž…ë‹ˆë‹¤.

> í•™ìŠµì‹œ ë§ˆë‹¤ íŒŒë¼ë¯¸í„° ì„¤ì •ê³¼ ê²½ê³¼ë“±ì„ ê¸°ë¡í•˜ì˜€ìœ¼ë‚˜ ì‚¬ë‚´ í”„ë¡œì íŠ¸ì¸ ê´€ê³„ë¡œ í•´ë‹¹ ë¶€ë¶„ ë¬¸ì„œëŠ” ê³µê°œí•˜ì§€ ì•Šìœ¼ë©°, ì´ë¡  ì •ë¦¬í•œ ë‚´ìš©ë§Œ ì—…ë¡œë“œë˜ì–´ ìžˆìŠµë‹ˆë‹¤.

[-> result_link](https://www.notion.so/6a7b84b4f2644738924fe0ec0adfb6fc)

## Voice Conversion Architecture
 
![voice_conversion_architecture](https://gitlab.com/hanish3464/voice-conversion/uploads/0ad08d0c271c97f6d0ceac56fbcc3388/voice_conversion_architecture.png)

## Our project
**ì´ í”„ë¡œì íŠ¸ì—ì„œëŠ” í•œêµ­ì–´ ìŒì„±ë³€ì¡°ëª¨ë¸ì„ ë§Œë“¤ì–´ ì• ë‹ˆë©”ì´ì…˜ ë”ë¹™ì— í™œìš©í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.**

* ì‚¬ìš©í•  ëª¨ë¸ : Cotatron
* ëª©í‘œ 
	* ì´ ëª¨ë¸ì€ ê¸°ì¡´ì— ì˜ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°œë°œë˜ì—ˆìœ¼ë¯€ë¡œ, ê³µê³µë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ í•œêµ­ì–´ ì…‹ì— ë§žë„ë¡ ìƒˆë¡œ í•™ìŠµì‹œí‚¤ê³  í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ”ë‹¤.
	* [ic data](https://github.com/Deplim/VoiceConversion_Doc/blob/main/2.%20%20MAIN%20-%20IC_data.md) ì„ ëŒ€ìƒìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì„±ëŠ¥ì„ í”„ë¡œì íŠ¸ì˜ ëª©ì ì— ë§žëŠ” ìˆ˜ì¤€ê¹Œì§€ ëŒì–´ì˜¬ë¦°ë‹¤. 

##  Any-to-many conversion
```
We propose Cotatron, a transcription-guided speech encoder for speaker-
independent linguistic representation. Cotatron is based on the multispeaker
TTS architecture and can be trained with conventional TTS datasets.
- Cotatron paper | Abstract íŒŒíŠ¸ ì´ˆìž…ë¶€ -
```
Cotatron ì—ì„œëŠ”  **í•™ìŠµë˜ì§€ ì•Šì€ speaker ì— ëŒ€í•´ì„œë„ ìž‘ë™í•  ìˆ˜ ìžˆë„ë¡ tts decoderë¥¼ í™œìš©í•œ ëŒ€ì‚¬ ê¸°ë°˜ speech encoder ì„ ì œì•ˆí•œë‹¤.**

-------
![voice_conversion_architecture2](https://gitlab.com/hanish3464/voice-conversion/uploads/48062a06512dbef141346bd0e8e4f1cf/voice_conversion_architecture2.png)
-------

voice conversion ë¶€ë¶„ì€ ì´ì „ ê¸°ìˆ ê³¼ ìœ ì‚¬í•˜ë‚˜, ì–¸ì–´(linguistic) ì ì¸ íŠ¹ì„±ì„ ë½‘ëŠ” ëª¨ë“ˆì—ì„œ ìƒˆë¡œìš´ ì œì•ˆì„ í•œ ê²ƒì´ íŠ¹ì§•ì´ë©°, ì´ ë¶€ë¶„ì„ **cotatron** ì´ë¼ ë¶€ë¥¸ë‹¤. 

### LEARNING

`ë³¸ ëª¨ë¸ì—ì„œ í•™ìŠµí•´ì•¼ í•˜ëŠ” íƒ€ê¹ƒì€ í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ì„¸ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤.`
* **í•™ìŠµ ëŒ€ìƒ**

	â–¶ TTS Decoder

	â–¶ Residual Encoder

	â–¶ Voice conversion Decoder


## Speech encoder
![voice_conversion_architecture3](https://gitlab.com/hanish3464/voice-conversion/uploads/504b8a0a845c9061baa60dc2303c9db5/voice_conversion_architecture3.PNG)

`ì´ íŒŒíŠ¸ì˜ speech encoder ëŠ” linguistic features ë¥¼ ë½‘ê¸° ìœ„í•œ cotatron ë¶€ë¶„ì„ ì§€ì¹­í•˜ëŠ” ê²ƒìœ¼ë¡œ, ì´ˆê¸°ê°’ mel-spectrogram ì„ ì „ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì¸ speaker encoder ì™€ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ì£¼ì˜í•  ê²ƒ.`

ìœ„ì˜ ê·¸ë¦¼ì´ speech encoder ì—ì„œ speaker encoding ê³¼ text encoding ë¥¼ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„ ì–¸ì–´ì ì¸ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ê³¼ì •ì´ë‹¤. 
**linguistic features L** ì´ ì—¬ê¸°ì„œ ë½‘ì¸ ì–¸ì–´ì ì¸ íŠ¹ì§•ì¸ë°, ì´ê²ƒì€ conversion ëª¨ë“ˆì˜ ìž…ë ¥ê°’ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤. 

ì´ë•Œ target speaker ID ë„ í•¨ê»˜ ìž…ë ¥ê°’ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ”ë° ì´ ê°’ì— ë”°ë¼ conversion ë„¤íŠ¸ì›Œí¬ê°€
ìž…ë ¥ê°’ì„ ì–´ë–¤ ì‚¬ëžŒì˜ ëª©ì†Œë¦¬ë¡œ ë³€í™˜í• ì§€ ê²°ì •ëœë‹¤.

## TTS Decoder 
`ì „ì²´ ì•„í‚¤í…ì²˜ì—ì„œ tts ë¶€ë¶„ë§Œì„ í™•ìž¥í•œ ê·¸ë¦¼ì´ë‹¤.`

![](https://gitlab.com/hanish3464/voice-conversion/uploads/ef4ab8ce74c7a0eb842932d7f11e9671/taco2tron_4_.png)

ttsëŠ” ëŒ€ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ìŒì„±ì„ ì¶œë ¥í•˜ëŠ” **text-to-speech** ëª¨ë¸ì„ ì˜ë¯¸í•œë‹¤. ì—¬ê¸°ì„œëŠ” ê·¸ ì¤‘ì—ì„œë„ **tacotron** ì´ë¼ëŠ” ëª¨ë¸ì´ ì‚¬ìš©ë˜ì—ˆë‹¤.

ì´ ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” í¬ê²Œ encoder íŒŒíŠ¸ì™€ decoder íŒŒíŠ¸ë¡œ ë‚˜ë‰˜ëŠ”ë°, cotatron ì€ encoder output ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì—¬ê¸°ì— **speaker encodingì„ concat í•˜ì—¬ ì‚¬ìš©**í•œë‹¤. cotatron ì•„í‚¤í…ì²˜ ì´ë¯¸ì§€ì—ì„œ text encoder ë¼ê³  ë˜ì–´ ìžˆëŠ” ëª¨ë“ˆì´ tacotron ì˜ encoder ì™€ ë™ì¼í•œ ê³„ì‚°ì„ í•˜ê³ , tts decoder ëª¨ë“ˆì´ tacotron ì˜ decoder ê³„ì‚°ì„ í•œë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. 

![cotatron2](https://gitlab.com/hanish3464/voice-conversion/uploads/32d272e00ce18c55eb0808787d91162a/cotatron2.png)

decoder ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì¶œë ¥ê°’ **mel-spectrogram** ì„ ê³„ì‚°í•˜ëŠ”ë° ì´ ê³¼ì •ì—ì„œ attention ê³„ì‚°ì´ ì§„í–‰ëœë‹¤. attention weight ëŠ” ê° ë””ì½”ë”ì—ì„œ ê° íƒ€ìž„ìŠ¤íƒ­ë§ˆë‹¤ ì¶œë ¥ê°’ì„ ê³„ì‚°í•˜ëŠ” ë° ìž…ë ¥ sequence ì¤‘ ì–´ë–¤ ì›ì†Œë¥¼ ì–¼ë§Œí¼ ì°¸ê³ í• ì§€ì˜ ë¹„ì¤‘ì— ëŒ€í•œ ê°’ì´ë‹¤.  cotatron ì—ì„œ tts decoder ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ë°”ë¡œ ì´ **attention weight ê°’ì„ ì´ìš©í•˜ì—¬ linguistic features ë¥¼ ë§Œë“¤ê¸°** ìœ„í•¨ì´ë‹¤. 

tts decoder ê° time step ì—ì„œ ë‚˜ì˜¨ attention weight ì˜ list ê°€ **alignment** ì´ë©°, ì´ê²ƒì„ voice conversion module ì˜ ìž…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.

`* tts decoder ì— ëŒ€í•´ ì´í•´í•˜ë ¤ë©´ ìš°ì„  ë‹¤ìŒ ìžë£Œë¥¼ ë¨¼ì € ì½ì„ ê²ƒì„ ì¶”ì²œí•¨. `
* [ìžì—°ì–´ì²˜ë¦¬ - Seq2seq.md](https://github.com/Deplim/VoiceConversion_Doc/blob/main/2-1.%20%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC%20%EC%A7%80%EC%8B%9D%20-%20Seq2seq.md)
* [ìžì—°ì–´ì²˜ë¦¬ - Bahdanau attention.md](https://github.com/Deplim/VoiceConversion_Doc/blob/main/2-2.%20%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC%20%EC%A7%80%EC%8B%9D%20-%20Bahdanau%20attention.md)
* [tts ê¸°ìˆ  - Tacotron.md](https://github.com/Deplim/VoiceConversion_Doc/blob/main/3.%20tts%20%EA%B8%B0%EC%88%A0%20-%20Tacotron.md)

### LEARNING
* **Loss** 

![](https://latex.codecogs.com/gif.latex?MSELoss%28melPred%2C%20melTarget%29%20&plus;%20MSELoss%28melPostNet%2C%20melTarget%29)

```
melTarget : source speaker audio ì˜ mel-spectrogram
melPred : tts decoder ì—ì„œ post net ì„ í†µê³¼í•˜ê¸° ì „ mel-spectrogram
melPostNet : tts decoder ì—ì„œ post net ì„ í†µê³¼í•œ í›„ì˜ mel-spectrogram
```

* **classifier Loss** 

![](https://latex.codecogs.com/gif.latex?nllLoss%28speackerProb%2C%20speakers%29)

```
speackerProb : speacker classifier ë¥¼ í†µí•´ ì˜ˆì¸¡í•œ ë°œí™”ìž (softmax ë¥¼ ê±°ì¹œ vector í˜•íƒœ)
speakers : ë°œí™”ìž id (ìž„ë² ë”©ëœ ìƒíƒœ)
```

* **target Weight**

	â–¶ Go-Frame : 
	```
	tss decoder ì—ì„œëŠ” ì´ì „ íƒ€ìž…ìŠ¤íƒ­ì˜ ê²°ê³¼ê°’ì„ ê°€ì ¸ì™€ ìž…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”ë°, ì²« íƒ€ìž„ìŠ¤íƒ­
	ì—ì„œëŠ” ê·¸ê²Œ ì•ˆë˜ë¯€ë¡œ, ì‹œìž‘ frame ì„ ìž„ì˜ë¡œ ë§Œë“¤ì–´ë‚´ëŠ”ë° ì´ê²ƒì´ go-frame.
	
	ë‹¨ìˆœížˆ í•œë²ˆ ì´ˆê¸°í™”ë˜ëŠ” ê²ƒì´ í•˜ë‹ˆë¼ back-propagtion ì˜ í•™ìŠµ ëŒ€ìƒì´ ë˜ì–´ ì—…ë°ì´íŠ¸ê°€
	ì§€ì†ì ìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤.
	```	
	â–¶ Attention Weight 
	```
	tacotron ì—ì„œëŠ” bahdanau attention ì´ ì“°ì´ëŠ”ë° ì—¬ê¸°ì—ì„œ ì“°ì´ëŠ” ê°€ì¤‘ì¹˜.
	
	ì—¬ê¸°ì„œ í•™ìŠµ ëŒ€ìƒì´ ë˜ëŠ” attention weight ì™€ ê³„ì‚° ê²°ê³¼ë¡œì¨ ì¶œë ¥ë˜ì–´ alignment ê³„ì‚°
	ì— ì‚¬ìš©ë˜ëŠ” attention weight ë¥¼ ìž˜ êµ¬ë¶„í•´ì•¼ í•¨.
	```
 	â–¶ Decoder Weight 
 	```
 	tts ì˜ decorder ë¶€ë¶„ rnn ì‹ ê²½ë§ì— ë“¤ì–´ê°€ëŠ” ê°€ì¤‘ì¹˜ë“¤ì„ ì˜ë¯¸.
 	```

## Alignment
alignment ëž€ ë””ì½”ë”ì˜ íŠ¹ì • time step ì´
**ì¸ì½”ë”ì˜ sequence ì¤‘ ì–´ëŠ ë¶€ë¶„ì— attention ì„ ë§Žì´ ë‘ëŠ”ê°€** ì— ëŒ€í•œ ì •ë³´ì˜ ë¦¬ìŠ¤íŠ¸ë¼ê³  í•  ìˆ˜ ìžˆë‹¤.

`ë‹¤ìŒì€ alignment ë¥¼ ê·¸ëž˜í”„ ìƒì— í‘œí˜„í•œ ê²ƒì´ë‹¤.`
![alignment](https://gitlab.com/hanish3464/voice-conversion/uploads/ed664690553edc51f1940a5b6e512d84/alignment.PNG)

ì˜ˆë¥¼ ë“¤ì–´ì„œ ë””ì½”ë”ì˜ n ë²ˆì§¸ íƒ€ìž„ ìŠ¤íƒ­ì— ëŒ€í•˜ì—¬ attention weight ë¥¼ ê³„ì‚°í–ˆì„ ë•Œ
ì¸ì½”ë” output ì¤‘ì— k ë²ˆì§¸ ì›ì†Œì— ëŒ€í•œ ê°’ì´ í¬ë‹¤ë©´,
ê·¸ëž˜í”„ì—ì„œ [Decoder time steps = n ,   Encoder states = k ] ì¸ ìœ„ì¹˜ì— ìƒ‰ìœ¼ë¡œ í‘œì‹œê°€ ë˜ëŠ”ê²ƒ.

ìœ„ ê·¸ëž˜í”„ì˜ ê²½ìš° **weight ê°€ í¬ë©´ í´ìˆ˜ë¡ ë°ì€ìƒ‰ìœ¼ë¡œ í‘œì‹œí•˜ë„ë¡** ë˜ì–´ìžˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìžˆë‹¤.

> ë‹¤ë¥¸ ìžë£Œë“¤ì—ì„œ alignment ì— ëŒ€í•˜ì—¬ **"ìŒì„±ê³¼ ëŒ€ì‚¬ë¥¼ ë§¤ì¹­í•˜ì—¬ ìœ ì‚¬í•œ ë¶€ë¶„ì„ ê³„ì‚°"** 
> í•œë‹¤ëŠ” í‘œí˜„ì´ ìžì£¼ ì“°ì´ëŠ” ê²ƒì´ ë°”ë¡œ ìœ„ì˜ ì´ìœ  ë•Œë¬¸ì´ë‹¤. 

ë”°ë¼ì„œ ê·¸ëž˜í”„ê°€ ì˜¤ë¥¸ìª½ ìœ„ë¡œ ëŠê¸°ì§€ ì•Šê³  ì—°ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì´ ê°€ìž¥ ì´ìƒì ì´ë‹¤.

![alignment2](https://gitlab.com/hanish3464/voice-conversion/uploads/86239843d9bd984194ff3af1d07e93a1/alignment2.PNG)

ë§Œì•½ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ê·¸ëž˜í”„ê°€ ê¹”ë”í•˜ì§€ ì•Šê³  íë ¤ì§€ëŠ” ë¶€ë¶„ì´ ìžˆë‹¤ë©´, í•´ë‹¹ time step ì—ì„œ ì–´ëŠ ê³³ì— attention ì„ ì¤„ì§€ ëª…í™•í•˜ê²Œ íŠ¹ì •ì§“ì§€ ëª»í•˜ê³  ìžˆë‹¤ëŠ” ëœ»ì´ë‹¤. 

## Linguistic Feature L
feature L ì€ alignment ì™€ text encoding ì˜ í–‰ë ¬ê³±, ì¦‰

![](https://latex.codecogs.com/gif.latex?L%3Dmatmul%28A%2C%20%5Cunderset%7Btext%7D%7BEncoder%7D%28T%29%29)

ì´ë‹¤.

feature L ì€ ì‚¬ì‹¤ìƒ ë””ì½”ë”ì—ì„œ ê³„ì‚°ë˜ëŠ” Attention value ì™€ ë™ì¼í•œ ê°’ì´ë‹¤.
(Attention value ë„ ì¸ì½”ë” ì¶œë ¥ê³¼ ì–´í…ì…˜ weightì˜ ê°€ì¤‘í•©ì´ë¯€ë¡œ)

## Voice Conversion Decoder

![VC_decoder](https://gitlab.com/hanish3464/voice-conversion/uploads/d22d0ed4c3fb5427cbe3e40902bfc659/VC_decoder.PNG)

### LEARNING

* **Loss**

![](https://latex.codecogs.com/gif.latex?MSELoss%28melSS%2C%20melTarget%29)

```
melTarget : source speaker audio ì˜ mel-spectrogram
melSS : conversion decoder ì˜ ê²°ê³¼ê°’ mel-spectrogram
```

* **Description**
    
    ![voice_conversion_learning](https://gitlab.com/hanish3464/voice-conversion/uploads/d4edc86f5c7f9b779c450ed1d4d65d62/voice_conversion_learning.png)

    **conversion decoder í•™ìŠµì—ì„œ source speaker ì™€ target speaker ëŠ” ë™ì¼í•œ ì‚¬ëžŒì´ë‹¤.**

    íŠ¹ì • speaker ì— ëŒ€í•´ í•™ìŠµì‹œí‚¤ë ¤ë©´ 
    > **íŠ¹ì • ëŒ€ì‚¬(1)** ì— ëŒ€í•˜ì—¬ **í•´ë‹¹ target speaker(2)** ê°€ ë…¹ìŒí•œ **ìŒì„±(3)** ì€ ë‹¤ìŒê³¼ ê°™ë‹¤

    ë¼ëŠ” ì‹ìœ¼ë¡œ ë°ì´í„°ê°€ í˜•ì„±ë˜ì–´ìžˆì–´ì•¼ í•œë‹¤. 

    target speaker ê°€ ì•„ë‹Œ ë‹¤ë¥¸ speaker ê°€ ê°™ì€ ëŒ€ì‚¬ë¥¼ ë…¹ìŒí•œ ê²ƒì´ ìžˆë‹¤ë©´ ë‹¤ë¥¸ speaker ì˜ ìŒì„± íŒŒì¼ì„ ì´ìš©í•˜ì—¬ linguistic feature ë¥¼ ì¶”ì¶œí•˜ì—¬ ì‚¬ìš©í•´ë„  ì¢‹ì„ ê²ƒì´ë‹¤. 
    (ìŒì„±ë³€ì¡°ë¼ëŠ” ëª©í‘œë¥¼ ìƒê°í•˜ë©´ ì§ê´€ì ìœ¼ë¡œ ë´¤ì„ë•Œ ì´ë ‡ê²Œ í•™ìŠµì‹œí‚¤ëŠ”ê²Œ ë” ì¢‹ì„ ê²ƒì´ë¼ê³  ìƒê°ë¨.)

    í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° í•˜ë‚˜ì˜ ëŒ€ì‚¬ì— ëŒ€í•˜ì—¬ í•œ í•œëª…ì˜ í™”ìžë§Œ ë…¹ìŒì„ í•˜ë¯€ë¡œ ê·¸ë ‡ê²Œ í•˜ê¸´ëŠ” íž˜ë“¤ë‹¤. ë•Œë¬¸ì— íŠ¹ì • source data ì—ì„œ feature L ì„ ì¶”ì¶œí•˜ì—¬ target speaker ì˜ ëª©ì†Œë¦¬ë¡œ ë³€í™˜í•˜ëŠ” conversion í•  ë•Œì—í•™ìŠµ ë ˆì´ë¸”ë¡œ ë‹¤ì‹œ source data ì˜ audio ê°€ ë“¤ì–´ê°€ê²Œë” ë˜ì–´ ìžˆëŠ” ê²ƒì´ë‹¤.


## Vocoder
(ìž‘ì„±ì˜ˆì •)

Cotatron ë…¼ë¬¸ â–¶
> [Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data. 2020](https://arxiv.org/abs/2005.03295) 
