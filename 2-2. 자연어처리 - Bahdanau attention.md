> 본 문서는 wikidocs **"딥러닝을 이용한 자연어 처리 입문"** 문서의 다음 파트를 참고하여 작성했습니다.
> * [# 바다나우 어텐션(Bahdanau Attention)](https://wikidocs.net/73161)

## Cotatron 에서의 Attention Mechanism 
Attention Mechanism 에는 다양한 종류가 있다. 그 중에서도 이번 프로젝트에서 사용하는 모델(cotatron) 중 tts(Tacotron 사용) 부분에 Bahdanau Attention 이 사용되어 본 문서를 작성한다. 

## Setting
* 어텐션 함수 Attention(Q, K, V)=Attention Value
```
t = 어텐션 메커니즘이 수행되는 디코더 셀의 현재 시점을 의미.  

Q = Query : t-1 시점의 디코더 셀에서의 은닉 상태  
K = Keys : 모든 시점의 인코더 셀의 은닉 상태들  
V = Values : 모든 시점의 인코더 셀의 은닉 상태들
```
`어텐션 함수의 Query 가 디코더 셀의 t 시점이 아니라 t-1 시점임을 주목`

`인코더의 은닉 상태와 디코더의 은닉 상태가 동일하다고 가정.`

`📑 기본적으로 사용하는 symbol 들은 dot-product 문서와 동일.`

## Architecture
```
기본적인 attention은 s_t 를 구한 후 인코더의 은닉 상태와 조합하여 새로 생성한 값을 
출력층에 입력하지만, Bahdanau Attention 에서는 그 이전 타임스탭인 s_{t-1} 을 활용하여
context vector 을 계산하고, 이것을 원래 입력값으로 들어가야 하는 배열과 concat 한 것이 입력값이 된다.

이후에 결과값 출력까지는 어텐션 메커니즘을 사용하지 않는 경우와 동일하다
```
![](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%985.PNG)

`이제 이 Context Vector 를 계산하기까지의 과정을 알아보자`
## Process

1. **어텐션 스코어 (Attention Score)**
	> Attention Mechanism 종류끼리의 차이는 대부분 score 계산 수식에서의 차이고, Bahdanau Attention 도 마찬가지이다.
![](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%981.PNG)
	
* 스코어 계산 식

![](https://latex.codecogs.com/gif.latex?score%28s_%7Bt-1%7D%2C%20h_i%29%20%3D%20W_a%5ET%20%5Ctanh%28W_b%20s_%7Bt-1%7D%20&plus;%20W_c%20h_i%29)

```
여기서 W_a, W_b, W_c 는 학습 가능한 가중치 행렬이다.
Cotatron 에서 Attention module 를 학습시킨다고 하는 것이 바로 이 값을 학습시킨다는
것이다.

h_i 는 각 인코더 셀의 은닉 상태를 의미한다.
```

* h_1, h_2, h_3, h_4 를 하나의 행렬 H 로 둘 경우

![](https://latex.codecogs.com/gif.latex?score%28s_%7Bt-1%7D%2C%20H%29%20%3D%20W_a%5ET%20%5Ctanh%28W_b%20s_%7Bt-1%7D%20&plus;%20W_c%20H%29)

```
여기서 각각의 h_i 에 대해서 계산한 다음 concat 하는 것이나 미리 합친 배열 H 로 계산하는
것이나 동일한 결과가 나온다. 다음 그림을 보자. 
```
![](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%982.PNG)
![](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%983.PNG)
```
W_c * H 에는 각 h_i 대한 연산결과가 열단위로 담겨있다.

tanh 를 적용하기 전, W_b * s_{t-1} + W_c * h_i 의 계산에서는  s_{t-1} 계산결과 쪽이
업 스캐일링 되어 더해진다.
(이부분은 확실하지 않으나, 맥락상 그런 것으로 추정됨)

하이퍼볼릭탄젠트 함수(tanh) 를 지난 후에 한번 더 가중치와 곱하면 Attention score 벡터를
얻는다.
```

2. **어텐션 분포(Attention Distribution)**
```
이부분은 기본적인 어텐션 분포와 동일하다. 
합이 1인 확률 분포로 변환하는 과정
```
![](https://wikidocs.net/images/page/73161/%EC%96%B4%ED%85%90%EC%85%98%EB%94%94%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B7%B0%EC%85%98.PNG)

`❗ 여기서 어텐션 분포 각각의 값인 어텐션 가중치(Attention Weight) 는 
가중치 W_a, W_b, W_c 와 다른 값임.
"학습 대상"인 어텐션 가중치와 "계산 결과"인 어텐션 가중치를 잘 구분해서 이해할 것.`

3. **어텐션 값(Attention Value)**
```
각 인코더의 은닉 상태와 어텐션 가중치 값을 곱한다.
```
![](https://wikidocs.net/images/page/73161/%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B2%A1%ED%84%B0.PNG)
* 이것을 인코더의 문맥을 포함하고 있다고 하여, **컨텍스트 벡터(context vector)** 라고 부름.

`❗ [Task 3 : Voice Conversion - Cotatron 코드 분석하기] 문서에서는 
Speaker feature 과 text feature 의 합을 context vector 라고 정의하는데 
이것과 다른 값이므로 혼동하지 말 것.`

4. **디코더 셀 결과값 계산** : <img src="https://latex.codecogs.com/svg.latex?s_t" />
```
컨텍스트 벡터(context vector) 과 현제 시점의 입력인 단어의 임베딩 벡터를 연결(concatenate) 하여 새로운 입력으로 사용
```
![](https://wikidocs.net/images/page/73161/LSTM.PNG)

* 계산한 <img src="https://latex.codecogs.com/svg.latex?s_t" /> 를 출력층으로 전달해 현재 시점의 예측값을 구하고, 다음 타임스탭으로 넘어가면서 반복
![](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%985.PNG)

`위에 나왔듯 입력값을 넣은 이후에는 어텐션 메커니즘을 사용하지 않는 경우와 동일함`
